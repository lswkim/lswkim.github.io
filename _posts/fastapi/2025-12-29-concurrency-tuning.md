---
title: "[FastAPI ì‹¤ì „ì‹¬í™” 3] ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ì™€ ì„±ëŠ¥ íŠœë‹"
date: 2025-12-29 12:00:00 +0900
categories: [Tech, FastAPI]
tags: [python, fastapi, concurrency, performance, tuning]
mermaid: true
---

> **ğŸ“š FastAPI ì‹œë¦¬ì¦ˆ - Part 5. ì‹¤ì „ ì‹¬í™”**
>
> 1. [ë™ê¸° í•¨ìˆ˜ vs ë¹„ë™ê¸° í•¨ìˆ˜ ì„ íƒ ê¸°ì¤€](/posts/sync-async-choice/)
> 2. [BackgroundTasksì™€ ì‘ì—… í](/posts/background-tasks/)
> 3. ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ì™€ ì„±ëŠ¥ íŠœë‹ â† í˜„ì¬ ê¸€
> 4. [FastAPI ì˜ˆì™¸ì²˜ë¦¬](/posts/exception-handling/)
> 5. [í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ê³„](/posts/project-structure/)
> 6. [Python ê°ì²´/ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ íŒ¨í„´](/posts/resource-management/)

---

# 3. ë™ì‹œ ìš”ì²­ ì²˜ë¦¬ì™€ ì„±ëŠ¥ íŠœë‹

## ì™œ ì´ ê°œë…ì´ ì¤‘ìš”í•œê°€?

- í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì•ˆì •ì ì¸ ì„œë¹„ìŠ¤ ìš´ì˜
- ë¦¬ì†ŒìŠ¤ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©
- ë³‘ëª© êµ¬ê°„ íŒŒì•… ë° ìµœì í™”

---

## FastAPI ë™ì‹œì„± ëª¨ë¸ ë³µìŠµ

```mermaid
flowchart TB
    subgraph Worker["Uvicorn Worker (í”„ë¡œì„¸ìŠ¤)"]
        subgraph EventLoop["ì´ë²¤íŠ¸ ë£¨í”„ (ë©”ì¸ ìŠ¤ë ˆë“œ)"]
            EL1[async def ì—”ë“œí¬ì¸íŠ¸ë“¤]
            EL2[ìˆ˜ì²œ ê°œ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥<br/>I/O ë°”ìš´ë“œ]
        end

        subgraph ThreadPool["ìŠ¤ë ˆë“œí’€ (ê¸°ë³¸ 40ê°œ)"]
            TP1[def ì—”ë“œí¬ì¸íŠ¸ë“¤]
            TP2[ë™ê¸° ë¸”ë¡œí‚¹ ì‘ì—… ì²˜ë¦¬]
        end
    end
```

---

## ì›Œì»¤ ìˆ˜ ì„¤ì •

### ê¸°ë³¸ ê³µì‹

| í™˜ê²½ | ì›Œì»¤ ìˆ˜ ê¶Œì¥ |
| --- | --- |
| **I/O ë°”ìš´ë“œ** (ëŒ€ë¶€ë¶„ì˜ API ì„œë²„) | 1 ~ CPU ì½”ì–´ ìˆ˜ (ë¹„ë™ê¸°ë¡œ ì´ë¯¸ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥) |
| **CPU ë°”ìš´ë“œ í˜¼í•©** | CPU ì½”ì–´ ìˆ˜ |
| **Kubernetes í™˜ê²½** | 1 (Pod ìˆ˜ë¡œ ìŠ¤ì¼€ì¼ë§) |

### ì„¤ì • ë°©ë²•

```bash
# Uvicorn ë‹¨ë…
uvicorn app:app --workers 4

# Gunicorn + Uvicorn
gunicorn app:app -w 4 -k uvicorn.workers.UvicornWorker

```

### ì›Œì»¤ ìˆ˜ì— ë”°ë¥¸ ë™ì‹œ ì²˜ë¦¬

4ì½”ì–´ ì„œë²„, async def ì—”ë“œí¬ì¸íŠ¸ (I/O ë°”ìš´ë“œ) ê¸°ì¤€:

| ì›Œì»¤ ìˆ˜ | ë™ì‹œ ì²˜ë¦¬ ëŠ¥ë ¥ |
| --- | --- |
| ì›Œì»¤ 1ê°œ | ìˆ˜ì²œ ê°œ ë™ì‹œ ì—°ê²° ì²˜ë¦¬ ê°€ëŠ¥ |
| ì›Œì»¤ 4ê°œ | ìˆ˜ì²œ Ã— 4 = ë” ë§ì€ ë™ì‹œ ì—°ê²° |

> I/O ë°”ìš´ë“œë©´ ì›Œì»¤ 1~2ê°œë¡œë„ ì¶©ë¶„í•œ ê²½ìš°ê°€ ë§ë‹¤. ì›Œì»¤ë¥¼ ëŠ˜ë¦¬ë©´ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ë„ ì¦ê°€í•œë‹¤ (í”„ë¡œì„¸ìŠ¤ë‹¹).

---

## ìŠ¤ë ˆë“œí’€ ì„¤ì •

### ê¸°ë³¸ ìŠ¤ë ˆë“œí’€ í¬ê¸°

```python
# Uvicorn ê¸°ë³¸: 40ê°œ
# def ì—”ë“œí¬ì¸íŠ¸ ë™ì‹œ ì²˜ë¦¬ ìˆ˜ = ìŠ¤ë ˆë“œí’€ í¬ê¸°

```

### ìŠ¤ë ˆë“œí’€ í¬ê¸° ì¡°ì •

```python
import asyncio
from concurrent.futures import ThreadPoolExecutor

@app.on_event("startup")
async def startup():
    loop = asyncio.get_event_loop()
    # ìŠ¤ë ˆë“œí’€ í¬ê¸°ë¥¼ 100ìœ¼ë¡œ ë³€ê²½
    loop.set_default_executor(ThreadPoolExecutor(max_workers=100))

```

### ì–¸ì œ ìŠ¤ë ˆë“œí’€ì„ ëŠ˜ë ¤ì•¼ í•˜ë‚˜?

| ìƒí™© | ì¡°ì • |
| --- | --- |
| def ì—”ë“œí¬ì¸íŠ¸ê°€ ë§ê³ , ë™ì‹œ ìš”ì²­ 40ê°œ ì´ìƒ ìì£¼ ë°œìƒ, ì‘ë‹µ ì‹œê°„ ëŠë ¤ì§ | **ëŠ˜ë ¤ì•¼ í•¨** |
| ë©”ëª¨ë¦¬ ë¶€ì¡±í•˜ê±°ë‚˜, ëŒ€ë¶€ë¶„ async def ì‚¬ìš© | **ì¤„ì—¬ì•¼ í•¨** |

> **ì£¼ì˜:** ìŠ¤ë ˆë“œê°€ ë§ë‹¤ê³  ë¬´ì¡°ê±´ ì¢‹ì€ ê²ƒì´ ì•„ë‹ˆë‹¤. ì»¨í…ìŠ¤íŠ¸ ìŠ¤ìœ„ì¹­ ì˜¤ë²„í—¤ë“œ ì¦ê°€í•˜ê³ , ìŠ¤ë ˆë“œë‹¹ ë©”ëª¨ë¦¬ ì‚¬ìš© (ì•½ 8MB ìŠ¤íƒ).

---

## ì—°ê²° ì œí•œ ì„¤ì •

### Uvicorn ì„¤ì •

```bash
uvicorn app:app \
    --limit-concurrency 1000 \    # ìµœëŒ€ ë™ì‹œ ì—°ê²°
    --limit-max-requests 10000 \  # ì›Œì»¤ë‹¹ ìµœëŒ€ ìš”ì²­ í›„ ì¬ì‹œì‘
    --timeout-keep-alive 5        # Keep-Alive íƒ€ì„ì•„ì›ƒ

```

### Gunicorn ì„¤ì •

```python
# gunicorn.conf.py
workers = 4
worker_class = "uvicorn.workers.UvicornWorker"

# ì›Œì»¤ ê´€ë¦¬
max_requests = 1000           # ìš”ì²­ í›„ ì›Œì»¤ ì¬ì‹œì‘ (ë©”ëª¨ë¦¬ ëˆ„ìˆ˜ ë°©ì§€)
max_requests_jitter = 50      # ë™ì‹œ ì¬ì‹œì‘ ë°©ì§€
timeout = 30                  # ìš”ì²­ íƒ€ì„ì•„ì›ƒ
graceful_timeout = 30         # ì¢…ë£Œ ëŒ€ê¸° ì‹œê°„
keepalive = 5                 # Keep-Alive íƒ€ì„ì•„ì›ƒ

```

---

## ë²¤ì¹˜ë§ˆí‚¹

### ë„êµ¬ ì„ íƒ

| ë„êµ¬ | íŠ¹ì§• | ì‚¬ìš© |
| --- | --- | --- |
| **wrk** | ë¹ ë¦„, ê°„ë‹¨ | ê¸°ë³¸ ë¶€í•˜ í…ŒìŠ¤íŠ¸ |
| **Locust** | Python, ì‹œë‚˜ë¦¬ì˜¤ ì‘ì„± | ë³µì¡í•œ ì‹œë‚˜ë¦¬ì˜¤ |
| **k6** | JavaScript, í˜„ëŒ€ì  | CI/CD í†µí•© |
| **ab** | Apache ê¸°ë³¸ | ê°„ë‹¨í•œ í…ŒìŠ¤íŠ¸ |
| **hey** | Go ê¸°ë°˜, ë¹ ë¦„ | ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ |

### wrk ê¸°ë³¸ ì‚¬ìš©

```bash
# ì„¤ì¹˜ (Ubuntu)
apt-get install wrk

# ê¸°ë³¸ í…ŒìŠ¤íŠ¸: 12ìŠ¤ë ˆë“œ, 400ì—°ê²°, 30ì´ˆ
wrk -t12 -c400 -d30s http://localhost:8000/api/endpoint

# ê²°ê³¼ ì˜ˆì‹œ
# Requests/sec: 15234.12
# Latency Avg: 26.12ms
# Latency 99%: 123.45ms

```

### Locust ì‚¬ìš©

```python
# locustfile.py
from locust import HttpUser, task, between

class APIUser(HttpUser):
    wait_time = between(1, 3)  # ìš”ì²­ ê°„ ëŒ€ê¸° ì‹œê°„

    @task(3)  # ê°€ì¤‘ì¹˜ 3
    def get_items(self):
        self.client.get("/items")

    @task(1)  # ê°€ì¤‘ì¹˜ 1
    def create_item(self):
        self.client.post("/items", json={"name": "test"})

    @task(2)
    def get_item(self):
        self.client.get("/items/1")

```

```bash
# ì‹¤í–‰
locust -f locustfile.py --host=http://localhost:8000

# ì›¹ UI: http://localhost:8089

```

### k6 ì‚¬ìš©

```javascript
// load_test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export const options = {
    stages: [
        { duration: '30s', target: 100 },  // ë¨í”„ì—…
        { duration: '1m', target: 100 },   // ìœ ì§€
        { duration: '30s', target: 0 },    // ë¨í”„ë‹¤ìš´
    ],
};

export default function () {
    const res = http.get('http://localhost:8000/items');
    check(res, {
        'status is 200': (r) => r.status === 200,
        'response time < 200ms': (r) => r.timings.duration < 200,
    });
    sleep(1);
}

```

```bash
# ì‹¤í–‰
k6 run load_test.js

```

---

## ì„±ëŠ¥ ì§€í‘œ (Metrics)

### í•µì‹¬ ì§€í‘œ

| ì§€í‘œ | ì„¤ëª… | ëª©í‘œ (ì˜ˆì‹œ) |
| --- | --- | --- |
| **RPS** | ì´ˆë‹¹ ìš”ì²­ ìˆ˜ | ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ |
| **Latency (Avg)** | í‰ê·  ì‘ë‹µ ì‹œê°„ | < 100ms |
| **Latency (p99)** | 99% ì‘ë‹µ ì‹œê°„ | < 500ms |
| **Error Rate** | ì—ëŸ¬ ë¹„ìœ¨ | < 0.1% |
| **Throughput** | ì²˜ë¦¬ëŸ‰ | ìš”êµ¬ì‚¬í•­ ì¶©ì¡± |

### ì§€í‘œ í•´ì„

| ìƒíƒœ | ì§€í‘œ ì˜ˆì‹œ |
| --- | --- |
| **ì¢‹ì€ ìƒíƒœ** | Avg Latency: 50ms, p99 Latency: 150ms, Error Rate: 0% |
| **ë¬¸ì œ ì§•í›„** | p99ê°€ Avgë³´ë‹¤ 10ë°° ì´ìƒ ë†’ìŒ â†’ ê°€ë” ëŠë¦° ìš”ì²­ ìˆìŒ, ë¶€í•˜ ì¦ê°€ ì‹œ Latency ê¸‰ì¦ â†’ ë³‘ëª© ìˆìŒ, Error Rate ì¦ê°€ â†’ ë¦¬ì†ŒìŠ¤ ë¶€ì¡± ë˜ëŠ” ë²„ê·¸ |

---

## ë³‘ëª© êµ¬ê°„ íŒŒì•…

### ì¼ë°˜ì ì¸ ë³‘ëª© êµ¬ê°„

```mermaid
flowchart TB
    subgraph DB["1. ë°ì´í„°ë² ì´ìŠ¤"]
        DB1[ìŠ¬ë¡œìš° ì¿¼ë¦¬]
        DB2[ì—°ê²° í’€ ë¶€ì¡±]
        DB3[ì¸ë±ìŠ¤ ëˆ„ë½]
    end

    subgraph API["2. ì™¸ë¶€ API"]
        API1[ëŠë¦° ì‘ë‹µ]
        API2[íƒ€ì„ì•„ì›ƒ ë¯¸ì„¤ì •]
        API3[ë™ê¸° í˜¸ì¶œ]
    end

    subgraph App["3. ì• í”Œë¦¬ì¼€ì´ì…˜"]
        App1[async def + ë¸”ë¡œí‚¹ í˜¸ì¶œ]
        App2[CPU ë°”ìš´ë“œ ì‘ì—…]
        App3[ë©”ëª¨ë¦¬ ëˆ„ìˆ˜]
    end

    subgraph Infra["4. ì¸í”„ë¼"]
        Infra1[ì›Œì»¤ ë¶€ì¡±]
        Infra2[ë©”ëª¨ë¦¬ ë¶€ì¡±]
        Infra3[ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­í­]
    end
```

### í”„ë¡œíŒŒì¼ë§ ë„êµ¬

```python
# 1. cProfile (ê¸°ë³¸)
import cProfile
import pstats

profiler = cProfile.Profile()
profiler.enable()
# ì½”ë“œ ì‹¤í–‰
profiler.disable()
stats = pstats.Stats(profiler).sort_stats('cumulative')
stats.print_stats(10)

# 2. py-spy (í”„ë¡œë•ì…˜ í”„ë¡œíŒŒì¼ë§)
# pip install py-spy
# py-spy top --pid <PID>
# py-spy record -o profile.svg --pid <PID>

# 3. line_profiler (ë¼ì¸ë³„ ë¶„ì„)
# pip install line_profiler
@profile
def slow_function():
    ...

```

### ìš”ì²­ë³„ íƒ€ì´ë° ì¸¡ì •

```python
import time
import logging

logger = logging.getLogger(__name__)

@app.middleware("http")
async def timing_middleware(request, call_next):
    start = time.perf_counter()

    response = await call_next(request)

    duration = time.perf_counter() - start

    # ëŠë¦° ìš”ì²­ ë¡œê¹…
    if duration > 1.0:  # 1ì´ˆ ì´ìƒ
        logger.warning(f"Slow request: {request.url.path} took {duration:.2f}s")

    response.headers["X-Response-Time"] = f"{duration:.4f}"
    return response

```

---

## ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”

### ì—°ê²° í’€ ì„¤ì •

```python
from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

engine = create_engine(
    DATABASE_URL,
    poolclass=QueuePool,
    pool_size=10,           # ê¸°ë³¸ ì—°ê²° ìˆ˜
    max_overflow=20,        # ì¶”ê°€ í—ˆìš© ì—°ê²°
    pool_timeout=30,        # ì—°ê²° ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ
    pool_recycle=1800,      # ì—°ê²° ì¬ìƒì„± ì£¼ê¸° (ì´ˆ)
    pool_pre_ping=True,     # ì—°ê²° ìœ íš¨ì„± ì²´í¬
)

```

### ë¹„ë™ê¸° DB (asyncpg)

```python
from sqlalchemy.ext.asyncio import create_async_engine, AsyncSession

engine = create_async_engine(
    "postgresql+asyncpg://user:pass@localhost/db",
    pool_size=10,
    max_overflow=20,
)

```

### ì—°ê²° í’€ í¬ê¸° ê³„ì‚°

**ê³µì‹ (ê¸°ë³¸):**
```
pool_size = (ì›Œì»¤ ìˆ˜ Ã— 2) + max_overflow
```

**ì˜ˆì‹œ (ì›Œì»¤ 4ê°œ):**
- pool_size = 10
- max_overflow = 20
- ìµœëŒ€ ì—°ê²° = 10 + 20 = 30

> **ì£¼ì˜:** DB ì„œë²„ì˜ max_connections í™•ì¸í•˜ê³ , ì—¬ëŸ¬ ì•±ì´ ê°™ì€ DB ì‚¬ìš© ì‹œ ë¶„ë°°ë¥¼ ê³ ë ¤í•œë‹¤.

---

## ì™¸ë¶€ API í˜¸ì¶œ ìµœì í™”

### ì—°ê²° ì¬ì‚¬ìš©

```python
import httpx

# âŒ ë§¤ ìš”ì²­ë§ˆë‹¤ ì—°ê²° ìƒì„±
@app.get("/external")
async def bad_external():
    async with httpx.AsyncClient() as client:
        response = await client.get("https://api.example.com")
    return response.json()

# âœ… ì—°ê²° ì¬ì‚¬ìš© (ì•± ìˆ˜ëª… ë™ì•ˆ)
http_client = None

@app.on_event("startup")
async def startup():
    global http_client
    http_client = httpx.AsyncClient(
        timeout=10.0,
        limits=httpx.Limits(max_connections=100)
    )

@app.on_event("shutdown")
async def shutdown():
    await http_client.aclose()

@app.get("/external")
async def good_external():
    response = await http_client.get("https://api.example.com")
    return response.json()

```

### íƒ€ì„ì•„ì›ƒ ì„¤ì •

```python
http_client = httpx.AsyncClient(
    timeout=httpx.Timeout(
        connect=5.0,    # ì—°ê²° íƒ€ì„ì•„ì›ƒ
        read=10.0,      # ì½ê¸° íƒ€ì„ì•„ì›ƒ
        write=10.0,     # ì“°ê¸° íƒ€ì„ì•„ì›ƒ
        pool=5.0,       # í’€ì—ì„œ ì—°ê²° ëŒ€ê¸° íƒ€ì„ì•„ì›ƒ
    )
)

```

---

## ìºì‹±

### Redis ìºì‹±

```python
import redis.asyncio as redis
import json

redis_client = redis.Redis(host='localhost', port=6379, db=0)

async def get_cached_or_fetch(key: str, fetch_func, ttl: int = 300):
    # ìºì‹œ í™•ì¸
    cached = await redis_client.get(key)
    if cached:
        return json.loads(cached)

    # ìºì‹œ ë¯¸ìŠ¤: ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
    data = await fetch_func()

    # ìºì‹œ ì €ì¥
    await redis_client.setex(key, ttl, json.dumps(data))

    return data

@app.get("/users/{user_id}")
async def get_user(user_id: int):
    return await get_cached_or_fetch(
        f"user:{user_id}",
        lambda: db.get_user(user_id),
        ttl=300
    )

```

### ì¸ë©”ëª¨ë¦¬ ìºì‹± (ê°„ë‹¨í•œ ê²½ìš°)

```python
from functools import lru_cache
from cachetools import TTLCache
import asyncio

# ë™ê¸° í•¨ìˆ˜ìš©
@lru_cache(maxsize=100)
def get_settings():
    return load_settings()

# ë¹„ë™ê¸°ìš© TTL ìºì‹œ
cache = TTLCache(maxsize=100, ttl=300)

async def get_cached_data(key: str):
    if key in cache:
        return cache[key]

    data = await fetch_data(key)
    cache[key] = data
    return data

```

---

## ìµœì í™” ì²´í¬ë¦¬ìŠ¤íŠ¸

### ë°°í¬ ì „ ì²´í¬ë¦¬ìŠ¤íŠ¸

- [ ] async def ì•ˆì—ì„œ ë¸”ë¡œí‚¹ í˜¸ì¶œ ì—†ëŠ”ì§€ í™•ì¸
- [ ] **ë°ì´í„°ë² ì´ìŠ¤**
  - [ ] ì—°ê²° í’€ ì„¤ì •
  - [ ] ìŠ¬ë¡œìš° ì¿¼ë¦¬ í™•ì¸
  - [ ] ì¸ë±ìŠ¤ í™•ì¸
- [ ] **ì™¸ë¶€ API**
  - [ ] íƒ€ì„ì•„ì›ƒ ì„¤ì •
  - [ ] ì—°ê²° ì¬ì‚¬ìš©
  - [ ] ì¬ì‹œë„ ë¡œì§
- [ ] **ìºì‹±**
  - [ ] ìì£¼ ì¡°íšŒë˜ëŠ” ë°ì´í„° ìºì‹±
  - [ ] TTL ì„¤ì •
- [ ] **ì„œë²„ ì„¤ì •**
  - [ ] ì›Œì»¤ ìˆ˜ ì ì ˆí•œì§€
  - [ ] ìŠ¤ë ˆë“œí’€ í¬ê¸° ì ì ˆí•œì§€
  - [ ] íƒ€ì„ì•„ì›ƒ ì„¤ì •
- [ ] **ëª¨ë‹ˆí„°ë§**
  - [ ] ì‘ë‹µ ì‹œê°„ ë¡œê¹…
  - [ ] ì—ëŸ¬ ì¶”ì 
  - [ ] ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§

### í™˜ê²½ë³„ ê¶Œì¥ ì„¤ì •

| í™˜ê²½ | ì›Œì»¤ | ìŠ¤ë ˆë“œí’€ | íŠ¹ì´ì‚¬í•­ |
| --- | --- | --- | --- |
| ê°œë°œ | 1 | ê¸°ë³¸(40) | `--reload` ì‚¬ìš© |
| ì†Œê·œëª¨ í”„ë¡œë•ì…˜ | 2~4 | 40~100 | Uvicorn ë‹¨ë… |
| ëŒ€ê·œëª¨ í”„ë¡œë•ì…˜ | CPU ìˆ˜ | ìƒí™©ì— ë§ê²Œ | Gunicorn + Uvicorn |
| Kubernetes | 1 | 40 | Pod ìˆ˜ë¡œ ìŠ¤ì¼€ì¼ë§ |

---

## í•µì‹¬ ì •ë¦¬

| í•­ëª© | ê¶Œì¥ |
| --- | --- |
| **ì›Œì»¤ ìˆ˜** | I/O ë°”ìš´ë“œ: 1~CPU ìˆ˜, K8s: 1 |
| **ìŠ¤ë ˆë“œí’€** | ê¸°ë³¸ 40, í•„ìš” ì‹œ ì¡°ì • |
| **DB ì—°ê²° í’€** | pool_size=10, max_overflow=20 |
| **ì™¸ë¶€ API** | ì—°ê²° ì¬ì‚¬ìš©, íƒ€ì„ì•„ì›ƒ í•„ìˆ˜ |
| **ìºì‹±** | ìì£¼ ì¡°íšŒ ë°ì´í„°ëŠ” Redis |

### ì„±ëŠ¥ íŠœë‹ ìˆœì„œ

1. ë²¤ì¹˜ë§ˆí‚¹ìœ¼ë¡œ í˜„ì¬ ìƒíƒœ íŒŒì•…
2. ë³‘ëª© êµ¬ê°„ ì‹ë³„ (DB? API? ì•±?)
3. í•´ë‹¹ êµ¬ê°„ ìµœì í™”
4. ë‹¤ì‹œ ë²¤ì¹˜ë§ˆí‚¹
5. ë°˜ë³µ

### ê°€ì¥ í”í•œ ë³‘ëª©

| ìˆœìœ„ | ì›ì¸ |
| --- | --- |
| 1ìœ„ | ë°ì´í„°ë² ì´ìŠ¤ (ìŠ¬ë¡œìš° ì¿¼ë¦¬, ì—°ê²° í’€ ë¶€ì¡±) |
| 2ìœ„ | async def + ë¸”ë¡œí‚¹ í˜¸ì¶œ |
| 3ìœ„ | ì™¸ë¶€ API (ëŠë¦° ì‘ë‹µ, íƒ€ì„ì•„ì›ƒ ì—†ìŒ) |
| 4ìœ„ | ìºì‹± ì—†ìŒ (ë§¤ë²ˆ ê°™ì€ ë°ì´í„° ì¡°íšŒ) |
