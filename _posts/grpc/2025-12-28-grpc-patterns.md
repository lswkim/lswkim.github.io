---
title: "4ê°€ì§€ í†µì‹  íŒ¨í„´"
date: 2025-12-28 21:00:00 +0900
categories: [Tech, gRPC]
tags: [grpc, streaming, unary, bidirectional]
mermaid: true
---

> **ğŸ“š gRPC ì‹œë¦¬ì¦ˆ - Part 2. gRPC í•µì‹¬ ê°œë…**
>
> 1. [.proto íŒŒì¼ê³¼ ì½”ë“œ ìƒì„±](/posts/proto-codegen/)
> 2. 4ê°€ì§€ í†µì‹  íŒ¨í„´ â† í˜„ì¬ ê¸€
> 3. [Channel, Metadata, Error Handling](/posts/grpc-advanced/)
> 4. [gRPC vs REST ë¹„êµ](/posts/grpc-vs-rest/)

---

## ì™œ ì´ê±¸ ì•Œì•„ì•¼ í•˜ëŠ”ê°€?

RESTëŠ” ìš”ì²­-ì‘ë‹µ í•˜ë‚˜ë¿ì´ë‹¤. gRPCëŠ” **4ê°€ì§€ íŒ¨í„´**ì„ ì§€ì›í•œë‹¤.

- LLM í† í° ìŠ¤íŠ¸ë¦¬ë° â†’ Server Streaming
- ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ â†’ Client Streaming
- ì‹¤ì‹œê°„ ì±„íŒ… â†’ Bidirectional Streaming

ìƒí™©ì— ë§ëŠ” íŒ¨í„´ì„ ì„ íƒí•´ì•¼ íš¨ìœ¨ì ì¸ ì„¤ê³„ê°€ ê°€ëŠ¥í•˜ë‹¤.

---

## 4ê°€ì§€ íŒ¨í„´ ê°œìš”

| íŒ¨í„´ | ìš”ì²­ | ì‘ë‹µ |
| --- | --- | --- |
| **Unary** | 1ê°œ | 1ê°œ |
| **Server Streaming** | 1ê°œ | Nê°œ |
| **Client Streaming** | Nê°œ | 1ê°œ |
| **Bidirectional Streaming** | Nê°œ | Nê°œ |

---

## 1. Unary RPC

### ê°œë…

```mermaid
sequenceDiagram
    participant C as Client
    participant S as Server

    C->>S: Request (1ê°œ)
    Note over S: ì²˜ë¦¬
    S->>C: Response (1ê°œ)
```

**ê°€ì¥ ì¼ë°˜ì ì¸ íŒ¨í„´.** REST APIì˜ ìš”ì²­-ì‘ë‹µê³¼ ë™ì¼í•˜ë‹¤.

### proto ì •ì˜

```protobuf
service UserService {
    rpc GetUser(GetUserRequest) returns (GetUserResponse);  // stream ì—†ìŒ
}
```

### ì„œë²„ êµ¬í˜„

```python
class UserServiceServicer(user_pb2_grpc.UserServiceServicer):

    def GetUser(self, request, context):
        user = db.get_user(request.id)
        return user_pb2.GetUserResponse(user=user)
```

### í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ

```python
# ì¼ë°˜ í•¨ìˆ˜ í˜¸ì¶œì²˜ëŸ¼ ì‚¬ìš©
response = stub.GetUser(user_pb2.GetUserRequest(id=123))
print(response.user.name)
```

### ì‚¬ìš© ì‚¬ë¡€

| ì‚¬ìš©ì²˜ | ì˜ˆì‹œ |
| --- | --- |
| CRUD ì‘ì—… | ìœ ì € ì¡°íšŒ, ìƒì„±, ìˆ˜ì •, ì‚­ì œ |
| ë‹¨ì¼ ì¶”ë¡  | ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì • ë¶„ì„ |
| ì„¤ì • ì¡°íšŒ | ì„œë²„ ì„¤ì •, í”¼ì²˜ í”Œë˜ê·¸ |

---

## 2. Server Streaming RPC

### ê°œë…

```mermaid
sequenceDiagram
    participant C as Client
    participant S as Server

    C->>S: Request (1ê°œ)
    S->>C: Response 1
    S->>C: Response 2
    S->>C: Response 3
    S->>C: ...
    S->>C: Response N (ì™„ë£Œ)
```

**ì„œë²„ê°€ ì—¬ëŸ¬ ì‘ë‹µì„ ìˆœì°¨ì ìœ¼ë¡œ ì „ì†¡.**

### proto ì •ì˜

```protobuf
service UserService {
    rpc ListUsers(ListUsersRequest) returns (stream User);  // ì‘ë‹µì— stream
}

service LLMService {
    rpc Generate(GenerateRequest) returns (stream Token);   // í† í° ìŠ¤íŠ¸ë¦¬ë°
}
```

### ì„œë²„ êµ¬í˜„

```python
class UserServiceServicer(user_pb2_grpc.UserServiceServicer):

    def ListUsers(self, request, context):
        users = db.get_all_users()

        # yieldë¡œ í•˜ë‚˜ì”© ì „ì†¡
        for user in users:
            yield user  # ê° userê°€ í´ë¼ì´ì–¸íŠ¸ë¡œ ì „ì†¡ë¨
```

### í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ

```python
# ì´í„°ë ˆì´í„°ë¡œ ë°›ìŒ
for user in stub.ListUsers(user_pb2.ListUsersRequest()):
    print(user.name)  # í•˜ë‚˜ì”© ë„ì°©í•  ë•Œë§ˆë‹¤ ì²˜ë¦¬
```

### ì‚¬ìš© ì‚¬ë¡€

| ì‚¬ìš©ì²˜ | ì˜ˆì‹œ |
| --- | --- |
| **LLM í† í° ìŠ¤íŠ¸ë¦¬ë°** | ChatGPTì²˜ëŸ¼ ê¸€ìê°€ í•˜ë‚˜ì”© ë‚˜ì˜¤ëŠ” íš¨ê³¼ |
| ëŒ€ìš©ëŸ‰ ëª©ë¡ ì¡°íšŒ | 10ë§Œ ê±´ ë°ì´í„°ë¥¼ ì²­í¬ë¡œ ì „ì†¡ |
| ì‹¤ì‹œê°„ í”¼ë“œ | ì£¼ì‹ ì‹œì„¸, ë¡œê·¸ ëª¨ë‹ˆí„°ë§ |

### LLM ìŠ¤íŠ¸ë¦¬ë° ì˜ˆì‹œ

```protobuf
// llm.proto
service LLMService {
    rpc Generate(GenerateRequest) returns (stream GenerateResponse);
}

message GenerateRequest {
    string prompt = 1;
    int32 max_tokens = 2;
}

message GenerateResponse {
    string token = 1;
    bool is_finished = 2;
}
```

```python
# ì„œë²„
class LLMServiceServicer(llm_pb2_grpc.LLMServiceServicer):

    def Generate(self, request, context):
        for token in llm.generate(request.prompt):
            yield llm_pb2.GenerateResponse(
                token=token,
                is_finished=False
            )

        yield llm_pb2.GenerateResponse(is_finished=True)

# í´ë¼ì´ì–¸íŠ¸
for response in stub.Generate(llm_pb2.GenerateRequest(prompt="ì•ˆë…•")):
    if not response.is_finished:
        print(response.token, end="", flush=True)  # í† í° í•˜ë‚˜ì”© ì¶œë ¥
```

---

## 3. Client Streaming RPC

### ê°œë…

```mermaid
sequenceDiagram
    participant C as Client
    participant S as Server

    C->>S: Request 1
    C->>S: Request 2
    C->>S: Request 3
    C->>S: ...
    C->>S: Request N (ì™„ë£Œ)
    Note over S: ì „ì²´ ì²˜ë¦¬
    S->>C: Response (1ê°œ)
```

**í´ë¼ì´ì–¸íŠ¸ê°€ ì—¬ëŸ¬ ìš”ì²­ì„ ë³´ë‚´ê³ , ì„œë²„ê°€ í•œ ë²ˆì— ì‘ë‹µ.**

### proto ì •ì˜

```protobuf
service FileService {
    rpc Upload(stream FileChunk) returns (UploadResponse);  // ìš”ì²­ì— stream
}

service DataService {
    rpc BatchInsert(stream Record) returns (BatchResponse);
}
```

### ì„œë²„ êµ¬í˜„

```python
class FileServiceServicer(file_pb2_grpc.FileServiceServicer):

    def Upload(self, request_iterator, context):
        total_size = 0
        file_data = b""

        # ì´í„°ë ˆì´í„°ë¡œ ìš”ì²­ë“¤ì„ ë°›ìŒ
        for chunk in request_iterator:
            file_data += chunk.data
            total_size += len(chunk.data)

        # íŒŒì¼ ì €ì¥
        save_file(file_data)

        # ìµœì¢… ì‘ë‹µ
        return file_pb2.UploadResponse(
            success=True,
            total_size=total_size
        )
```

### í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ

```python
def generate_chunks(file_path):
    """íŒŒì¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ ì„œ yield"""
    with open(file_path, 'rb') as f:
        while True:
            chunk = f.read(1024 * 1024)  # 1MBì”©
            if not chunk:
                break
            yield file_pb2.FileChunk(data=chunk)

# ì œë„ˆë ˆì´í„°ë¥¼ ì „ë‹¬
response = stub.Upload(generate_chunks("/path/to/large_file.zip"))
print(f"Uploaded: {response.total_size} bytes")
```

### ì‚¬ìš© ì‚¬ë¡€

| ì‚¬ìš©ì²˜ | ì˜ˆì‹œ |
| --- | --- |
| ëŒ€ìš©ëŸ‰ íŒŒì¼ ì—…ë¡œë“œ | ì˜ìƒ, ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ |
| ë°°ì¹˜ ì‚½ì… | ëŒ€ëŸ‰ ë°ì´í„° í•œ ë²ˆì— ì „ì†¡ |
| IoT ì„¼ì„œ ë°ì´í„° | ì„¼ì„œ ê°’ë“¤ì„ ëª¨ì•„ì„œ ì²˜ë¦¬ |

---

## 4. Bidirectional Streaming RPC

### ê°œë…

```mermaid
sequenceDiagram
    participant C as Client
    participant S as Server

    C->>S: Request 1
    S->>C: Response 1
    C->>S: Request 2
    C->>S: Request 3
    S->>C: Response 2
    S->>C: Response 3
    C->>S: Request 4
    S->>C: Response 4
```

**ì–‘ìª½ì´ ë…ë¦½ì ìœ¼ë¡œ ìŠ¤íŠ¸ë¦¬ë°.** ìˆœì„œë‚˜ íƒ€ì´ë° ì œì•½ ì—†ìŒ.

### proto ì •ì˜

```protobuf
service ChatService {
    rpc Chat(stream ChatMessage) returns (stream ChatMessage);  // ì–‘ìª½ stream
}
```

### ì„œë²„ êµ¬í˜„

```python
class ChatServiceServicer(chat_pb2_grpc.ChatServiceServicer):

    def Chat(self, request_iterator, context):
        for message in request_iterator:
            # í´ë¼ì´ì–¸íŠ¸ ë©”ì‹œì§€ ì²˜ë¦¬
            print(f"Received: {message.content}")

            # ì‘ë‹µ ìƒì„± ë° ì „ì†¡
            response = process_message(message)
            yield chat_pb2.ChatMessage(content=response)
```

### í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œ

```python
import threading
import queue

def run_chat():
    # ë³´ë‚¼ ë©”ì‹œì§€ í
    outgoing = queue.Queue()

    def generate_messages():
        while True:
            msg = outgoing.get()
            if msg is None:
                break
            yield chat_pb2.ChatMessage(content=msg)

    # ì–‘ë°©í–¥ ìŠ¤íŠ¸ë¦¼ ì‹œì‘
    responses = stub.Chat(generate_messages())

    # ì‘ë‹µ ìˆ˜ì‹  ìŠ¤ë ˆë“œ
    def receive():
        for response in responses:
            print(f"Server: {response.content}")

    recv_thread = threading.Thread(target=receive)
    recv_thread.start()

    # ë©”ì‹œì§€ ì „ì†¡
    while True:
        user_input = input("You: ")
        if user_input == "quit":
            outgoing.put(None)
            break
        outgoing.put(user_input)

    recv_thread.join()
```

### ì‚¬ìš© ì‚¬ë¡€

| ì‚¬ìš©ì²˜ | ì˜ˆì‹œ |
| --- | --- |
| ì‹¤ì‹œê°„ ì±„íŒ… | ë©”ì‹ ì €, ìƒë‹´ ì±—ë´‡ |
| ê²Œì„ ì„œë²„ | ì‹¤ì‹œê°„ ë©€í‹°í”Œë ˆì´ì–´ |
| í˜‘ì—… ë„êµ¬ | ë™ì‹œ í¸ì§‘, í™”ì´íŠ¸ë³´ë“œ |
| ìŒì„±/ì˜ìƒ í†µí™” | ì–‘ë°©í–¥ ë¯¸ë””ì–´ ìŠ¤íŠ¸ë¦¬ë° |

---

## íŒ¨í„´ ë¹„êµ ì •ë¦¬

| íŒ¨í„´ | ìš”ì²­ | ì‘ë‹µ | ì‚¬ìš© ì‚¬ë¡€ |
| --- | --- | --- | --- |
| **Unary** | 1ê°œ | 1ê°œ | ì¼ë°˜ API í˜¸ì¶œ |
| **Server Stream** | 1ê°œ | Nê°œ | LLM í† í° ìŠ¤íŠ¸ë¦¬ë°, ëŒ€ìš©ëŸ‰ ëª©ë¡ ì¡°íšŒ |
| **Client Stream** | Nê°œ | 1ê°œ | íŒŒì¼ ì—…ë¡œë“œ, ë°°ì¹˜ ë°ì´í„° ì „ì†¡ |
| **Bidirectional** | Nê°œ | Nê°œ | ì‹¤ì‹œê°„ ì±„íŒ…, ê²Œì„, í˜‘ì—… ë„êµ¬ |

---

## proto ë¬¸ë²• ì •ë¦¬

```protobuf
service MyService {
    // Unary - stream í‚¤ì›Œë“œ ì—†ìŒ
    rpc Method1(Request) returns (Response);

    // Server Streaming - ì‘ë‹µì— stream
    rpc Method2(Request) returns (stream Response);

    // Client Streaming - ìš”ì²­ì— stream
    rpc Method3(stream Request) returns (Response);

    // Bidirectional - ì–‘ìª½ì— stream
    rpc Method4(stream Request) returns (stream Response);
}
```

---

## MLOps ê´€ì ì—ì„œ í™œìš©

```mermaid
flowchart TB
    subgraph Patterns["ML ì„œë¹„ìŠ¤ì—ì„œì˜ íŒ¨í„´ ì„ íƒ"]
        subgraph Unary["Unary"]
            U1["ì´ë¯¸ì§€ ë¶„ë¥˜, ê°ì • ë¶„ì„ ë“± ë‹¨ì¼ ì¶”ë¡ "]
            U2["Triton Inference Server ê¸°ë³¸ í˜¸ì¶œ"]
        end

        subgraph ServerStream["Server Streaming"]
            S1["LLM í† í° ìŠ¤íŠ¸ë¦¬ë° (vLLM, TGI)"]
            S2["ê¸´ ì¶”ë¡  ê²°ê³¼ë¥¼ ì²­í¬ë¡œ ë°˜í™˜"]
        end

        subgraph ClientStream["Client Streaming"]
            C1["ëŒ€ìš©ëŸ‰ ëª¨ë¸ íŒŒì¼ ì—…ë¡œë“œ"]
            C2["ë°°ì¹˜ ì¶”ë¡ ìš© ë°ì´í„° ì „ì†¡"]
        end

        subgraph Bidirectional["Bidirectional"]
            B1["ì‹¤ì‹œê°„ ëŒ€í™”í˜• AI (ìŒì„± ë¹„ì„œ)"]
            B2["ì—°ì†ì ì¸ ì…ë ¥-ì¶œë ¥ (ì‹¤ì‹œê°„ ë²ˆì—­)"]
        end
    end
```

---

## í•µì‹¬ ì •ë¦¬

| íŒ¨í„´ | í‚¤ì›Œë“œ | í•µì‹¬ |
| --- | --- | --- |
| **Unary** | ì—†ìŒ | RESTì²˜ëŸ¼ 1:1 |
| **Server Streaming** | `returns (stream X)` | ì„œë²„ê°€ ì—¬ëŸ¬ ë²ˆ ì‘ë‹µ |
| **Client Streaming** | `(stream X) returns` | í´ë¼ì´ì–¸íŠ¸ê°€ ì—¬ëŸ¬ ë²ˆ ìš”ì²­ |
| **Bidirectional** | ì–‘ìª½ `stream` | ì‹¤ì‹œê°„ ì–‘ë°©í–¥ |
